---
title: "Plan generation"
---

# Plan generation

## Introduction

Once an agent has decomposed a complex task into subtasks (covered in the [previous lesson](./03-task-decomposition.md)), it needs to organize those subtasks into an actionable plan. Plan generation is the process of creating a structured, executable sequence of steps that includes not just *what* to do, but *how* to do it, *what resources* are needed, and *how long* each step should take.

Think of the difference between a to-do list and a project plan. A to-do list says "buy groceries." A project plan says "Drive to Whole Foods (15 min), buy items from the produce and dairy sections (20 min), drive home (15 min) â€” total 50 minutes, requires car and shopping list." Plan generation transforms the agent's decomposed subtasks into this level of specificity.

### What we'll cover

- Initial plan creation and representation formats
- Step specification with clear success criteria
- Resource identification and allocation
- Timeline estimation for agent tasks
- Implementation patterns for plan-generating agents

### Prerequisites

- Understanding of [task decomposition](./03-task-decomposition.md) â€” how complex tasks break into subtasks
- Familiarity with [agent architecture](../02-agent-architecture/00-agent-architecture.md)
- Basic Python knowledge

---

## Initial plan creation

Plan creation is where the agent transforms an abstract goal into a concrete sequence of steps. The quality of this initial plan determines whether the agent will succeed or waste cycles on dead-end approaches.

### What makes a good plan

A good agent plan has five properties:

| Property | Description | Bad example | Good example |
|----------|-------------|-------------|-------------|
| **Specific** | Each step describes a concrete action | "Research the topic" | "Search for 2024 revenue data for Company X" |
| **Ordered** | Steps follow a logical sequence | Random list of tasks | Dependencies mapped, critical path identified |
| **Measurable** | Each step has a clear success condition | "Understand the data" | "Extract revenue, profit margin, and growth rate" |
| **Bounded** | The plan has a defined end state | Open-ended exploration | "Plan complete when comparison table is filled" |
| **Recoverable** | Includes fallback options for failures | No error handling | "If API fails, try web search as backup" |

### Plan representation formats

Agents can represent plans in several ways, each with trade-offs:

#### Natural language plans

The simplest approach â€” the agent describes its plan in prose:

```
Plan: First, I'll look up the current stock price for each of the three
companies. Then I'll calculate the year-over-year change for each. Finally,
I'll rank them by performance and present the results in a table.
```

**Pros:** Easy to generate, human-readable, flexible.
**Cons:** Ambiguous, hard to track progress, difficult to parallelize.

#### Structured plans (recommended)

Use a structured format that's both human-readable and machine-parseable:

```python
from pydantic import BaseModel, Field

class PlanStep(BaseModel):
    """A single step in an agent's execution plan."""
    step_number: int
    action: str = Field(description="What to do")
    tool: str = Field(description="Which tool to use")
    inputs: dict = Field(description="Parameters for the tool")
    expected_output: str = Field(description="What success looks like")
    depends_on: list[int] = Field(
        default_factory=list,
        description="Step numbers that must complete first"
    )
    fallback: str | None = Field(
        default=None,
        description="What to do if this step fails"
    )
    estimated_seconds: int = Field(
        default=30,
        description="Estimated execution time"
    )

class ExecutionPlan(BaseModel):
    """A complete plan generated by the planning agent."""
    goal: str
    steps: list[PlanStep]
    total_estimated_seconds: int
    success_criteria: str
```

#### Formal plans (DAG representation)

For complex tasks, represent the plan as a directed acyclic graph with typed edges:

```python
from dataclasses import dataclass, field
from enum import Enum

class EdgeType(Enum):
    DATA = "data"           # Step B needs data from step A
    ORDER = "order"         # Step B must run after step A
    CONDITIONAL = "conditional"  # Step B runs only if step A succeeds

@dataclass
class PlanEdge:
    from_step: int
    to_step: int
    edge_type: EdgeType
    condition: str | None = None  # For conditional edges

@dataclass
class FormalPlan:
    steps: dict[int, PlanStep]
    edges: list[PlanEdge]

    def get_execution_waves(self) -> list[list[int]]:
        """Group steps into parallel execution waves."""
        completed: set[int] = set()
        waves: list[list[int]] = []

        while len(completed) < len(self.steps):
            wave = []
            for step_id, step in self.steps.items():
                if step_id in completed:
                    continue
                deps = [
                    e.from_step for e in self.edges
                    if e.to_step == step_id
                ]
                if all(d in completed for d in deps):
                    wave.append(step_id)
            waves.append(wave)
            completed.update(wave)

        return waves
```

### Building a plan-generating agent

Here's a complete example of an agent that generates structured plans:

```python
from agents import Agent, Runner

planner_agent = Agent(
    name="strategic_planner",
    instructions="""You are a planning agent. Given a goal, create a
    detailed execution plan.

    For EACH step in your plan, specify:
    1. A specific, actionable description
    2. Which tool to use (research, analyze, calculate, write, or validate)
    3. The exact inputs needed
    4. What successful completion looks like
    5. Dependencies on other steps (by step number)
    6. A fallback strategy if the step fails
    7. Estimated time in seconds

    Output your plan as a structured ExecutionPlan.

    Guidelines:
    - Prefer parallel steps where possible
    - Keep each step focused on ONE action
    - Include validation steps after critical operations
    - Total plan should have 4-10 steps (not too few, not too many)""",
    output_type=ExecutionPlan,
)

async def generate_plan(goal: str) -> ExecutionPlan:
    result = await Runner.run(planner_agent, goal)
    plan = result.final_output
    print(f"Plan for: {plan.goal}")
    print(f"Steps: {len(plan.steps)}")
    print(f"Estimated time: {plan.total_estimated_seconds}s")
    for step in plan.steps:
        deps = f" (after steps {step.depends_on})" if step.depends_on else " (no deps)"
        print(f"  {step.step_number}. [{step.tool}] {step.action}{deps}")
    return plan
```

**Output:**
```
Plan for: Analyze competitor pricing strategies
Steps: 6
Estimated time: 180s
  1. [research] Gather pricing data for Competitor A (no deps)
  2. [research] Gather pricing data for Competitor B (no deps)
  3. [research] Gather pricing data for Competitor C (no deps)
  4. [analyze] Compare pricing models and identify patterns (after steps [1, 2, 3])
  5. [calculate] Calculate price-to-feature ratios (after steps [4])
  6. [write] Generate pricing strategy recommendations (after steps [4, 5])
```

---

## Step specification

Each step in a plan needs to be specific enough that an executing agent (or a different agent) can carry it out without ambiguity. This is where many plans fail â€” steps that are too vague lead to inconsistent execution.

### The SMART step framework

Adapt the SMART criteria for agent plan steps:

| Criterion | Agent Plan Interpretation | Example |
|-----------|--------------------------|---------|
| **Specific** | Names the exact tool and parameters | "Call `search(query='AAPL stock price')`" |
| **Measurable** | Defines what the output should contain | "Result must include current price and 52-week range" |
| **Achievable** | Uses available tools and resources | Don't reference tools the agent doesn't have |
| **Relevant** | Directly contributes to the goal | Every step moves toward the success criteria |
| **Time-bound** | Has an estimated duration and timeout | "Expected to complete in 5-10 seconds" |

### Specifying inputs and outputs

Each step should clearly define its interface â€” what it receives and what it produces:

```python
class DetailedStep(BaseModel):
    """A fully specified plan step with clear interfaces."""

    # Identity
    step_number: int
    name: str                    # Short identifier (e.g., "fetch_revenue")
    description: str             # Human-readable description

    # Execution
    tool: str                    # Tool to invoke
    input_params: dict           # Exact parameters for the tool
    input_sources: dict = {}     # Where dynamic inputs come from
    # Example: {"company_name": "step_2.output.company"}

    # Success criteria
    expected_output_type: str    # "string", "number", "json", "list"
    output_schema: dict = {}     # Expected structure of the output
    validation_rules: list[str] = []  # Rules to check output against
    # Example: ["output.revenue > 0", "output.currency == 'USD'"]

    # Error handling
    max_retries: int = 2
    retry_delay_seconds: int = 5
    fallback_tool: str | None = None
    fallback_params: dict = {}

    # Timing
    estimated_seconds: int = 30
    timeout_seconds: int = 60
```

### Example: fully specified step

```python
step = DetailedStep(
    step_number=1,
    name="fetch_apple_revenue",
    description="Retrieve Apple's most recent quarterly revenue figure",
    tool="financial_data_api",
    input_params={
        "ticker": "AAPL",
        "metric": "quarterly_revenue",
        "period": "latest",
    },
    expected_output_type="json",
    output_schema={
        "revenue": "float",
        "currency": "str",
        "period": "str",
        "source": "str",
    },
    validation_rules=[
        "output.revenue > 0",
        "output.currency == 'USD'",
        "output.period contains '2024' or '2025'",
    ],
    max_retries=2,
    retry_delay_seconds=5,
    fallback_tool="web_search",
    fallback_params={"query": "Apple quarterly revenue latest 2025"},
    estimated_seconds=10,
    timeout_seconds=30,
)
```

> **ðŸ”‘ Key concept:** The more specific your step specification, the more reliably an agent can execute it. Vague steps like "research the company" force the executing agent to make implicit decisions that may not align with the planner's intent.

---

## Resource identification

Plans don't execute in a vacuum. Each step requires resources â€” tools, API credits, data access, computational capacity, and time. Identifying these resources upfront prevents failures mid-execution.

### Types of resources

| Resource type | Examples | Planning concern |
|------|------|------|
| **Tools** | Search API, database, calculator | Is the tool available? Authenticated? |
| **Data** | Training data, knowledge base, prior results | Is the data accessible and up to date? |
| **API quotas** | Rate limits, credit balances | Can we make enough calls for the plan? |
| **Compute** | CPU, GPU, memory | Do we have capacity for heavy processing? |
| **Time** | Deadline constraints, timeout limits | Can the plan complete within the allowed time? |
| **Human input** | Approvals, feedback, clarification | Are required humans available? |

### Resource-aware planning

Here's how to build resource awareness into plan generation:

```python
from dataclasses import dataclass

@dataclass
class ResourceBudget:
    """Available resources for plan execution."""
    max_tool_calls: int = 20       # Total tool calls allowed
    max_api_cost_usd: float = 1.0  # Maximum API spending
    max_execution_seconds: int = 300  # 5-minute timeout
    available_tools: list[str] = None  # Which tools are accessible
    requires_human_approval: bool = False

    def can_afford_step(self, step: PlanStep) -> bool:
        """Check if we have resources for this step."""
        if self.available_tools and step.tool not in self.available_tools:
            return False
        return True

    def estimate_plan_cost(self, plan: ExecutionPlan) -> dict:
        """Estimate total resource usage for a plan."""
        return {
            "total_tool_calls": len(plan.steps),
            "estimated_time": plan.total_estimated_seconds,
            "within_budget": (
                len(plan.steps) <= self.max_tool_calls
                and plan.total_estimated_seconds <= self.max_execution_seconds
            ),
        }

# Use the budget when generating plans
budget = ResourceBudget(
    max_tool_calls=15,
    max_execution_seconds=120,
    available_tools=["research", "calculate", "write"],
)

planner = Agent(
    name="resource_aware_planner",
    instructions=f"""Create an execution plan within these constraints:
    - Maximum {budget.max_tool_calls} tool calls
    - Must complete within {budget.max_execution_seconds} seconds
    - Available tools: {budget.available_tools}

    If the task cannot be completed within these constraints,
    explain what would need to change.""",
    output_type=ExecutionPlan,
)
```

**Output:**
```
Plan estimate:
  Total tool calls: 8 (budget: 15) âœ…
  Estimated time: 95s (budget: 120s) âœ…
  Within budget: True
```

### Handling resource constraints

When resources are insufficient for the ideal plan, the agent should adapt:

```python
def adapt_plan_to_budget(
    plan: ExecutionPlan,
    budget: ResourceBudget,
) -> ExecutionPlan:
    """Modify a plan to fit within resource constraints."""
    if len(plan.steps) > budget.max_tool_calls:
        # Strategy 1: Merge similar steps
        # Strategy 2: Remove optional validation steps
        # Strategy 3: Reduce scope
        pass

    if plan.total_estimated_seconds > budget.max_execution_seconds:
        # Strategy 1: Increase parallelism
        # Strategy 2: Use faster but less accurate tools
        # Strategy 3: Reduce the number of data points
        pass

    return plan
```

> **ðŸ¤– AI Context:** Resource awareness becomes critical in production agent systems. An agent that generates a 50-step plan costing $10 in API calls for a simple question is wasteful. Google ADK's `generate_content_config` allows setting `max_output_tokens` to constrain the planning budget itself.

---

## Timeline estimation

Estimating how long a plan will take helps users set expectations and allows the system to detect when an agent is stuck.

### Factors affecting execution time

| Factor | Impact | Example |
|--------|--------|---------|
| Tool latency | Direct â€” each tool call takes time | API calls: 0.5-5s, web searches: 1-10s |
| LLM reasoning | Per-turn overhead | Each Think step: 1-5s depending on model |
| Sequential depth | Multiplied by dependency chains | 5 sequential steps Ã— 3s each = 15s minimum |
| Parallel width | Reduced by concurrent execution | 3 parallel steps take the time of the slowest one |
| Retry probability | Adds contingency time | 10% failure rate per step adds ~10% to total time |

### Computing timeline estimates

```python
from dataclasses import dataclass

@dataclass
class TimelineEstimate:
    """Estimated execution timeline for a plan."""
    optimistic_seconds: float    # Everything works first try
    expected_seconds: float      # Normal execution with some variability
    pessimistic_seconds: float   # Multiple retries, slow responses

    @classmethod
    def from_plan(cls, plan: ExecutionPlan) -> "TimelineEstimate":
        """Calculate timeline from plan structure."""
        # Calculate per-step timing
        step_times = {
            s.step_number: s.estimated_seconds for s in plan.steps
        }

        # Find execution waves (groups of parallel steps)
        waves = _compute_waves(plan)

        # Optimistic: fastest path, no retries
        optimistic = sum(
            min(step_times[s] for s in wave) if len(wave) > 1
            else step_times[wave[0]]
            for wave in waves
        )

        # Expected: max of each parallel wave + overhead
        expected = sum(
            max(step_times[s] for s in wave)
            for wave in waves
        ) * 1.2  # 20% overhead for LLM reasoning

        # Pessimistic: expected + retry budget
        pessimistic = expected * 1.5  # 50% contingency

        return cls(
            optimistic_seconds=optimistic,
            expected_seconds=expected,
            pessimistic_seconds=pessimistic,
        )

def _compute_waves(plan: ExecutionPlan) -> list[list[int]]:
    """Group plan steps into parallel execution waves."""
    completed = set()
    waves = []
    step_deps = {s.step_number: set(s.depends_on) for s in plan.steps}

    while len(completed) < len(plan.steps):
        wave = [
            s_num for s_num, deps in step_deps.items()
            if s_num not in completed and deps.issubset(completed)
        ]
        if not wave:
            break
        waves.append(wave)
        completed.update(wave)

    return waves

# Usage
timeline = TimelineEstimate.from_plan(plan)
print(f"Optimistic: {timeline.optimistic_seconds:.0f}s")
print(f"Expected:   {timeline.expected_seconds:.0f}s")
print(f"Pessimistic: {timeline.pessimistic_seconds:.0f}s")
```

**Output:**
```
Optimistic: 35s
Expected:   84s
Pessimistic: 126s
```

---

## Best practices

| Practice | Why it matters |
|----------|----------------|
| Use structured plan formats | Machine-parseable plans enable automated execution and monitoring |
| Specify success criteria for each step | Without criteria, you can't know if a step truly completed |
| Include fallback strategies | Plans that only work on the happy path fail in production |
| Estimate resources before executing | Prevents mid-plan failures due to quota exhaustion |
| Provide three-point time estimates | Optimistic/expected/pessimistic sets realistic expectations |
| Separate planning from execution | The planner agent should not execute â€” use dedicated workers |

---

## Common pitfalls

| âŒ Mistake | âœ… Solution |
|-----------|-------------|
| Plans without success criteria | Every step needs a measurable "done" condition |
| Ignoring resource limits | Check tool availability and API quotas before execution |
| Over-planning simple tasks | A 2-step task doesn't need a 10-step formal plan |
| No fallback strategies | Include at least one alternative for every critical step |
| Static plans with no adaptation | Plans should be living documents â€” revise when conditions change |

---

## Hands-on exercise

### Your task

Build a plan-generating agent that creates detailed, resource-aware execution plans with timeline estimates.

### Requirements

1. Create an `ExecutionPlan` model with `PlanStep` items including tools, inputs, dependencies, and fallbacks
2. Build an agent that generates a plan for: "Create a comprehensive comparison of Python web frameworks (Django, FastAPI, Flask) for a new project"
3. Add resource budget validation (max 12 tool calls, max 120 seconds)
4. Calculate optimistic, expected, and pessimistic timeline estimates
5. Print the plan with execution waves showing parallel opportunities

### Expected result

A structured plan with 6-10 steps, grouped into 3-4 execution waves, with timeline estimates and resource validation.

<details>
<summary>ðŸ’¡ Hints (click to expand)</summary>

- Research for each framework can run in parallel (wave 1)
- Comparison and analysis depends on all research (wave 2)
- Report writing depends on analysis (wave 3)
- Use `output_type=ExecutionPlan` on the planner agent for structured output
- Each research step should specify what data points to collect (stars, downloads, performance benchmarks, etc.)

</details>

<details>
<summary>âœ… Solution (click to expand)</summary>

```python
import asyncio
from pydantic import BaseModel, Field
from agents import Agent, Runner

class PlanStep(BaseModel):
    step_number: int
    action: str
    tool: str
    inputs: dict
    expected_output: str
    depends_on: list[int] = []
    fallback: str | None = None
    estimated_seconds: int = 30

class ExecutionPlan(BaseModel):
    goal: str
    steps: list[PlanStep]
    total_estimated_seconds: int
    success_criteria: str

planner = Agent(
    name="framework_comparison_planner",
    instructions="""Create a plan to compare Python web frameworks.

    Available tools: research, analyze, calculate, write
    Budget: max 12 tool calls, max 120 seconds total
    
    For each step specify: action, tool, inputs, expected output,
    dependencies, fallback strategy, and time estimate.
    
    Maximize parallelism where possible.""",
    output_type=ExecutionPlan,
)

async def main():
    result = await Runner.run(
        planner,
        "Compare Django, FastAPI, and Flask for a new web project"
    )
    plan = result.final_output

    # Validate resource budget
    budget_ok = len(plan.steps) <= 12 and plan.total_estimated_seconds <= 120
    print(f"Budget check: {'âœ… PASS' if budget_ok else 'âŒ FAIL'}")
    print(f"  Steps: {len(plan.steps)}/12")
    print(f"  Time: {plan.total_estimated_seconds}/120s")

    # Print execution waves
    print(f"\nPlan: {plan.goal}")
    for step in plan.steps:
        deps = f" â†’ after [{', '.join(str(d) for d in step.depends_on)}]" if step.depends_on else ""
        print(f"  {step.step_number}. [{step.tool}] {step.action} (~{step.estimated_seconds}s){deps}")

    print(f"\nSuccess criteria: {plan.success_criteria}")

asyncio.run(main())
```

**Expected output:**
```
Budget check: âœ… PASS
  Steps: 8/12
  Time: 95/120s

Plan: Compare Django, FastAPI, and Flask
  1. [research] Research Django features and benchmarks (~15s)
  2. [research] Research FastAPI features and benchmarks (~15s)
  3. [research] Research Flask features and benchmarks (~15s)
  4. [analyze] Compare performance benchmarks (~10s) â†’ after [1, 2, 3]
  5. [analyze] Compare ecosystem and community metrics (~10s) â†’ after [1, 2, 3]
  6. [calculate] Score frameworks on weighted criteria (~5s) â†’ after [4, 5]
  7. [write] Generate comparison report with recommendations (~20s) â†’ after [6]
  8. [write] Create summary table (~5s) â†’ after [7]

Success criteria: Complete comparison covering performance, features, ecosystem, learning curve with clear recommendation
```

</details>

### Bonus challenges

- [ ] Add a `ResourceBudget` constraint check that rejects plans exceeding the budget
- [ ] Implement the `TimelineEstimate` class and calculate three-point estimates for the generated plan
- [ ] Make the planner adapt the plan when given a tighter budget (e.g., max 6 tool calls)

---

## Summary

âœ… Plan generation transforms decomposed subtasks into **specific, ordered, measurable, bounded, and recoverable** execution steps

âœ… Use **structured plan formats** (Pydantic models) over natural language â€” they enable automated execution, validation, and monitoring

âœ… Each step should specify the **tool, inputs, expected output, dependencies, and fallback strategy** â€” the SMART step framework

âœ… **Resource identification** upfront prevents mid-execution failures from quota exhaustion or missing tools

âœ… **Timeline estimation** with three-point estimates (optimistic/expected/pessimistic) sets realistic expectations and detects stuck agents

**Next:** [Plan Validation](./05-plan-validation.md)

---

## Further reading

- [Anthropic: Building Effective Agents](https://www.anthropic.com/engineering/building-effective-agents) â€” Agent design principles and composable patterns
- [Google ADK: Planner Configuration](https://google.github.io/adk-docs/agents/llm-agents/#planner) â€” BuiltInPlanner and PlanReActPlanner
- [OpenAI Agents SDK: Structured Output](https://openai.github.io/openai-agents-python/agents/#output-types) â€” Using `output_type` for plan generation
- [OpenAI: A Practical Guide to Building Agents](https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf) â€” Agent planning strategies

*[Back to Reasoning & Planning Overview](./00-reasoning-planning.md)*

<!--
Sources Consulted:
- Anthropic Building Effective Agents (composable patterns, tool documentation): https://www.anthropic.com/engineering/building-effective-agents
- Google ADK LLM Agents (PlanReActPlanner, BuiltInPlanner, generate_content_config): https://google.github.io/adk-docs/agents/llm-agents/
- OpenAI Agents SDK (output_type, structured output, Pydantic models): https://openai.github.io/openai-agents-python/agents/
- LangGraph overview (state management, graph compilation): https://docs.langchain.com/oss/python/langgraph/overview
-->
