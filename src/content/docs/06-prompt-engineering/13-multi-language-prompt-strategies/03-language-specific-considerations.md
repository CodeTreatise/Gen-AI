---
title: "Language-Specific Considerations"
---

# Language-Specific Considerations

## Introduction

Every language has unique characteristics that affect how AI models process and generate text. From grammatical gender in German to honorific systems in Korean, these differences directly impact prompt effectiveness and output quality. This lesson examines the linguistic features you must account for when prompting in specific languages.

> **ğŸ”‘ Key Insight:** Understanding tokenization costs alone can reduce your API expenses by 50%+ when working with non-Latin scripts.

### What We'll Cover

- Grammar and structural differences across languages
- Formality and honorific systems
- Script considerations (CJK, RTL, diacritics)
- Tokenization efficiency by language
- Language-specific prompt optimizations

### Prerequisites

- [Prompting in Different Languages](./01-prompting-in-different-languages.md)
- [Cross-Lingual Engineering](./02-cross-lingual-engineering.md)

---

## Grammar and Structural Differences

### Word Order Variations

| Language | Default Word Order | Example | Impact on Prompts |
|----------|-------------------|---------|-------------------|
| English | SVO (Subject-Verb-Object) | "The cat catches the mouse" | Standard reference |
| Japanese | SOV (Subject-Object-Verb) | "çŒ«ãŒãƒã‚ºãƒŸã‚’æ•ã¾ãˆã‚‹" | Place key info at end |
| Arabic | VSO (Verb-Subject-Object) | "ÙŠÙ…Ø³Ùƒ Ø§Ù„Ù‚Ø· Ø§Ù„ÙØ£Ø±" | Action-first framing |
| German | V2 (Verb-second) | "Die Katze fÃ¤ngt die Maus" | Verb placement rules |
| Welsh | VSO | "Mae'r gath yn dal y llygoden" | Similar to Arabic |

### Grammatical Gender

Languages with grammatical gender require consistent agreement:

```python
# âŒ Will produce inconsistent output
prompt_no_gender = """
Write about a doctor and their assistant.
"""

# âœ… Spanish - specify gender if needed
prompt_spanish = """
Escribe sobre una doctora (femenino) y su asistente (masculino).
MantÃ©n la concordancia de gÃ©nero en todo el texto.
"""

# âœ… German - three genders to manage
prompt_german = """
Schreiben Sie Ã¼ber einen Arzt (maskulin) und seine Assistentin (feminin).
Achten Sie auf korrekte Genus-Ãœbereinstimmung.
"""
```

### Case Systems

Languages like German, Russian, Finnish, and Latin have case systems:

```python
# German case system impact on outputs
german_cases = {
    "nominative": "der Mann (the man - subject)",
    "accusative": "den Mann (the man - direct object)",
    "dative": "dem Mann (to/for the man - indirect object)",
    "genitive": "des Mannes (of the man - possession)"
}

# Prompt for German with case awareness
prompt = """
Schreiben Sie einen Text Ã¼ber den neuen Mitarbeiter.
Achten Sie auf die korrekte Verwendung der vier FÃ¤lle:
- Nominativ fÃ¼r Subjekte
- Akkusativ fÃ¼r direkte Objekte
- Dativ fÃ¼r indirekte Objekte
- Genitiv fÃ¼r Besitz

Beispiel: Der Mitarbeiter (Nom) gibt dem Chef (Dat) den Bericht (Akk).
"""
```

### Verb Conjugation Complexity

| Language | Conjugation Forms | Example (to speak) |
|----------|-------------------|-------------------|
| English | ~5 forms | speak, speaks, spoke, spoken, speaking |
| Spanish | 50+ forms | hablo, hablas, habla, hablamos... |
| Finnish | 100+ forms | puhun, puhut, puhuu, puhumme... |
| Turkish | 100+ forms | Agglutinative suffixes |

```python
# For highly conjugated languages, provide context
spanish_prompt = """
Responde usando:
- Tiempo: presente del indicativo
- Persona: primera persona del plural (nosotros)
- Registro: formal

Ejemplo correcto: "Nosotros trabajamos..."
Ejemplo incorrecto: "TrabajÃ©..." (tiempo incorrecto)
"""
```

---

## Formality and Honorific Systems

### Formality Levels by Language

```mermaid
graph TD
    A[Formality Complexity] --> B[Binary Systems]
    A --> C[Multiple Levels]
    A --> D[Hierarchical Systems]
    
    B --> E[German: du/Sie]
    B --> F[French: tu/vous]
    B --> G[Spanish: tÃº/usted]
    
    C --> H[Portuguese: tu/vocÃª/o senhor]
    C --> I[Indonesian: kamu/Anda/Bapak]
    
    D --> J[Japanese: 7+ levels]
    D --> K[Korean: 7 speech levels]
    D --> L[Javanese: 3+ registers]
```

### Japanese Keigo (æ•¬èª) System

```python
# Japanese honorific levels
keigo_levels = {
    "casual": {
        "name": "ã‚¿ãƒ¡å£ (tameguchi)",
        "use": "Close friends, family",
        "example": "é£Ÿã¹ã‚‹ (taberu - eat)"
    },
    "polite": {
        "name": "ä¸å¯§èª (teineigo)",
        "use": "General politeness, strangers",
        "example": "é£Ÿã¹ã¾ã™ (tabemasu - eat)"
    },
    "respectful": {
        "name": "å°Šæ•¬èª (sonkeigo)",
        "use": "Honoring others' actions",
        "example": "å¬ã—ä¸ŠãŒã‚‹ (meshiagaru - eat [honorific])"
    },
    "humble": {
        "name": "è¬™è­²èª (kenjougo)",
        "use": "Humbling own actions",
        "example": "ã„ãŸã ã (itadaku - eat [humble])"
    },
    "super_polite": {
        "name": "æœ€é«˜æ•¬èª (saikoukeigo)",
        "use": "Imperial family, extreme formality",
        "example": "Rarely used"
    }
}

# Prompt for specific formality
japanese_prompt = """
ä»¥ä¸‹ã®ãƒ¡ãƒ¼ãƒ«ã‚’ä¸å¯§èªã§æ›¸ã„ã¦ãã ã•ã„ã€‚
æ•¬èªã®ãƒ¬ãƒ™ãƒ«ï¼šä¸å¯§èªï¼ˆã§ã™ãƒ»ã¾ã™èª¿ï¼‰
ç›¸æ‰‹ï¼šå–å¼•å…ˆã®æ‹…å½“è€…
å ´é¢ï¼šãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒ¼ãƒ«

æ–‡æœ«ã¯ã€Œã§ã™ã€ã€Œã¾ã™ã€ã§çµ±ä¸€ã—ã¦ãã ã•ã„ã€‚
å°Šæ•¬èªã¨è¬™è­²èªã‚’é©åˆ‡ã«ä½¿ã„åˆ†ã‘ã¦ãã ã•ã„ã€‚
"""
```

### Korean Speech Levels

```python
# Korean has 7 speech levels - most commonly use 4
korean_levels = {
    "hasoseoche": {
        "level": 1,
        "formality": "Highest formal",
        "usage": "Announcements, military, very formal writing",
        "ending": "-ìŠµë‹ˆë‹¤/-ã…‚ë‹ˆë‹¤"
    },
    "haeyoche": {
        "level": 2,
        "formality": "Polite/formal",
        "usage": "Business, news, formal conversation",
        "ending": "-ì•„ìš”/-ì–´ìš”"
    },
    "haeche": {
        "level": 3,
        "formality": "Casual polite",
        "usage": "Between close acquaintances",
        "ending": "-ì•„/-ì–´"
    },
    "banmal": {
        "level": 4,
        "formality": "Casual/intimate",
        "usage": "Close friends, younger people",
        "ending": "-ì•„/-ì–´ (no ìš”)"
    }
}

# Korean formality prompt
korean_prompt = """
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•´ìš”ì²´(ì¡´ëŒ“ë§)ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
ìƒí™©: ê³ ê° ì„œë¹„ìŠ¤ ì‘ëŒ€
ë¬¸ì²´: ì¹œê·¼í•˜ì§€ë§Œ ì¡´ì¤‘í•˜ëŠ” ì–´ì¡°
ë¬¸ì¥ ëì—ëŠ” "~ì•„ìš”/~ì–´ìš”"ë¥¼ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.
"""
```

### Arabic Formal/Informal Distinction

```python
# Arabic formality
arabic_prompt = """
Ø§ÙƒØªØ¨ Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ (MSA).
Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø±Ø³Ù…ÙŠ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù…Ø±Ø§Ø³Ù„Ø§Øª Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ©.
ØªØ¬Ù†Ø¨ Ø§Ù„Ø¹Ø§Ù…ÙŠØ© ÙˆØ§Ù„Ù„Ù‡Ø¬Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©.

Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø±Ø³Ù…ÙŠØ©: Ø±Ø³Ù…ÙŠ
Ø§Ù„Ø¬Ù…Ù‡ÙˆØ± Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù: Ø´Ø±ÙƒØ§Ø¡ Ø§Ù„Ø¹Ù…Ù„
"""
# Translation: Write in Modern Standard Arabic (MSA), 
# formal style for business correspondence,
# avoid colloquial and local dialects
```

---

## Script Considerations

### Character Set Categories

| Category | Languages | Characteristics | LLM Support |
|----------|-----------|-----------------|-------------|
| **Latin Extended** | European languages | Diacritics, special chars | Excellent |
| **CJK** | Chinese, Japanese, Korean | Logographic/mixed | Very Good |
| **Arabic Script** | Arabic, Persian, Urdu | RTL, contextual forms | Good |
| **Devanagari** | Hindi, Sanskrit, Marathi | Abugida script | Good |
| **Cyrillic** | Russian, Ukrainian, Bulgarian | Alphabet | Excellent |
| **Thai/Lao** | Thai, Lao | No word spaces | Good |

### Right-to-Left (RTL) Languages

```python
# RTL considerations for Arabic, Hebrew, Persian, Urdu
rtl_prompt = """
Ø§ÙƒØªØ¨ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ÙŠÙ…ÙŠÙ† Ø¥Ù„Ù‰ Ø§Ù„ÙŠØ³Ø§Ø±.
Ø¹Ù†Ø¯ ØªØ¶Ù…ÙŠÙ† Ø£Ø±Ù‚Ø§Ù… Ø£Ùˆ Ù†Øµ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØŒ Ø³ÙŠØ¸Ù‡Ø± Ù…Ù† Ø§Ù„ÙŠØ³Ø§Ø± Ø¥Ù„Ù‰ Ø§Ù„ÙŠÙ…ÙŠÙ† Ø¯Ø§Ø®Ù„ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ.

Ù…Ø«Ø§Ù„ ØµØ­ÙŠØ­:
Ø§Ù„Ø³Ø¹Ø± Ù‡Ùˆ 100 Ø¯ÙˆÙ„Ø§Ø±.
(The price is $100)
"""

# Handling mixed RTL/LTR in output
def format_rtl_output(arabic_text: str, numbers: list[str]) -> str:
    """Ensure proper RTL/LTR mixing in output."""
    # RTL mark and LTR mark for explicit direction
    RLM = '\u200F'  # Right-to-Left Mark
    LRM = '\u200E'  # Left-to-Right Mark
    
    result = f"{RLM}{arabic_text}"
    for num in numbers:
        result = result.replace(num, f"{LRM}{num}{RLM}")
    
    return result
```

### CJK (Chinese, Japanese, Korean) Scripts

```python
# CJK-specific considerations
cjk_guidelines = """
CJK OUTPUT GUIDELINES:

Chinese (ä¸­æ–‡):
- Simplified (ç®€ä½“) or Traditional (ç¹é«”) - specify which
- Punctuation: Use full-width ã€‚ï¼Œï¼ï¼Ÿ not .!?
- Numbers: Can use Arabic (1,2,3) or Chinese (ä¸€,äºŒ,ä¸‰)

Japanese (æ—¥æœ¬èª):
- Use appropriate mix of kanji, hiragana, katakana
- Katakana for foreign words: ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ¼ (computer)
- Full-width punctuation: ã€‚ã€ï¼ï¼Ÿ

Korean (í•œêµ­ì–´):
- Hangul is primary, hanja (Chinese characters) rare
- Spaces between words (unlike Chinese/Japanese)
- Full-width punctuation typically used
"""

# Specify script variant
chinese_prompt = """
è¯·ç”¨ç®€ä½“ä¸­æ–‡å›ç­”ã€‚
ä½¿ç”¨å…¨è§’æ ‡ç‚¹ç¬¦å·ï¼ˆã€‚ï¼Œï¼ï¼Ÿï¼‰
æ•°å­—ä½¿ç”¨é˜¿æ‹‰ä¼¯æ•°å­—ï¼ˆ1ã€2ã€3ï¼‰
"""
```

### Languages Without Word Spaces

```python
# Thai, Lao, Khmer, Burmese, Japanese, Chinese don't use spaces
# This affects tokenization and output parsing

thai_prompt = """
à¸à¸£à¸¸à¸“à¸²à¹€à¸‚à¸µà¸¢à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸¡à¸²à¸•à¸£à¸à¸²à¸™
à¹ƒà¸Šà¹‰à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸«à¸¡à¸²à¸¢à¸§à¸£à¸£à¸„à¸•à¸­à¸™à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡
à¹à¸¢à¸à¸›à¸£à¸°à¹‚à¸¢à¸„à¸”à¹‰à¸§à¸¢à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸«à¸¡à¸²à¸¢ à¸¯ à¸«à¸£à¸·à¸­à¸Šà¹ˆà¸­à¸‡à¸§à¹ˆà¸²à¸‡à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡
"""
# Note: Parsing Thai output requires language-specific tokenization
```

---

## Tokenization Efficiency

### Token Costs by Language

```python
# Approximate token efficiency compared to English baseline
tokenization_efficiency = {
    # Tier 1: Most efficient (similar to English)
    "english": {"chars_per_token": 4.0, "cost_multiplier": 1.0},
    "spanish": {"chars_per_token": 4.1, "cost_multiplier": 1.0},
    "french": {"chars_per_token": 4.0, "cost_multiplier": 1.0},
    "german": {"chars_per_token": 3.8, "cost_multiplier": 1.05},
    "italian": {"chars_per_token": 4.2, "cost_multiplier": 0.95},
    "portuguese": {"chars_per_token": 4.1, "cost_multiplier": 1.0},
    
    # Tier 2: Moderate overhead (Cyrillic, Greek)
    "russian": {"chars_per_token": 2.5, "cost_multiplier": 1.6},
    "ukrainian": {"chars_per_token": 2.4, "cost_multiplier": 1.7},
    "greek": {"chars_per_token": 2.8, "cost_multiplier": 1.4},
    
    # Tier 3: Higher overhead (CJK)
    "japanese": {"chars_per_token": 1.5, "cost_multiplier": 2.7},
    "chinese": {"chars_per_token": 1.2, "cost_multiplier": 3.3},
    "korean": {"chars_per_token": 1.8, "cost_multiplier": 2.2},
    
    # Tier 4: Significant overhead
    "thai": {"chars_per_token": 1.0, "cost_multiplier": 4.0},
    "arabic": {"chars_per_token": 2.0, "cost_multiplier": 2.0},
    "hindi": {"chars_per_token": 1.5, "cost_multiplier": 2.7},
    
    # Tier 5: Highest overhead
    "burmese": {"chars_per_token": 0.8, "cost_multiplier": 5.0},
    "tibetan": {"chars_per_token": 0.7, "cost_multiplier": 5.7}
}
```

### Cost Calculation Example

```python
def estimate_token_cost(
    text: str,
    source_language: str,
    target_language: str,
    cost_per_1k_tokens: float = 0.01
) -> dict:
    """Estimate token costs for translation task."""
    
    # Get efficiency data
    source_eff = tokenization_efficiency.get(source_language, {"cost_multiplier": 1.0})
    target_eff = tokenization_efficiency.get(target_language, {"cost_multiplier": 1.0})
    
    # Estimate character counts
    source_chars = len(text)
    # Rough estimate: translations are similar length in characters
    estimated_target_chars = source_chars
    
    # Calculate tokens
    source_tokens = source_chars / (source_eff.get("chars_per_token", 4.0))
    target_tokens = estimated_target_chars / (target_eff.get("chars_per_token", 4.0))
    
    total_tokens = source_tokens + target_tokens
    cost = (total_tokens / 1000) * cost_per_1k_tokens
    
    return {
        "source_tokens": int(source_tokens),
        "target_tokens": int(target_tokens),
        "total_tokens": int(total_tokens),
        "estimated_cost": round(cost, 4),
        "cost_vs_english": round(
            (source_eff["cost_multiplier"] + target_eff["cost_multiplier"]) / 2, 
            2
        )
    }

# Example: English to Japanese translation
result = estimate_token_cost(
    text="This is a sample text for translation that demonstrates cost differences.",
    source_language="english",
    target_language="japanese"
)
print(result)
# Output: {'source_tokens': 17, 'target_tokens': 46, 'total_tokens': 63, 
#          'estimated_cost': 0.0006, 'cost_vs_english': 1.85}
```

### Tokenization Visualization

```python
import tiktoken

def visualize_tokenization(text: str, model: str = "gpt-4"):
    """Visualize how text is tokenized."""
    
    encoding = tiktoken.encoding_for_model(model)
    tokens = encoding.encode(text)
    
    print(f"Text: {text}")
    print(f"Total tokens: {len(tokens)}")
    print(f"Characters: {len(text)}")
    print(f"Chars/token: {len(text)/len(tokens):.1f}")
    print("\nTokens:")
    for token in tokens:
        decoded = encoding.decode([token])
        print(f"  {token}: '{decoded}'")

# English: efficient tokenization
visualize_tokenization("The quick brown fox jumps")
# Output: 5 tokens, ~4.8 chars/token

# Japanese: less efficient
visualize_tokenization("ç´ æ—©ã„èŒ¶è‰²ã®ç‹ãŒã‚¸ãƒ£ãƒ³ãƒ—ã™ã‚‹")
# Output: ~15 tokens, ~1.1 chars/token

# Chinese: each character often = 1 token
visualize_tokenization("æ•æ·çš„æ£•è‰²ç‹ç‹¸è·³è¿‡")
# Output: ~10 tokens, ~0.9 chars/token
```

---

## Language-Specific Prompt Optimizations

### Strategy by Language Family

```python
class LanguageOptimizer:
    """Optimize prompts for specific languages."""
    
    strategies = {
        "latin_european": {
            "languages": ["english", "spanish", "french", "german", "italian", "portuguese"],
            "tips": [
                "Standard prompting works well",
                "Can use English prompts with target language instruction",
                "Few-shot examples effective",
                "Formality is main cultural variable"
            ]
        },
        "cjk": {
            "languages": ["chinese", "japanese", "korean"],
            "tips": [
                "Native language prompts often outperform",
                "Keep prompts concise (tokenization cost)",
                "Use language-specific punctuation",
                "Provide formality level explicitly (especially Japanese/Korean)"
            ]
        },
        "arabic_script": {
            "languages": ["arabic", "persian", "urdu"],
            "tips": [
                "Specify MSA vs dialect for Arabic",
                "Account for RTL in formatting",
                "Be aware of diglossia (formal vs spoken)",
                "Test with native speakers"
            ]
        },
        "indic": {
            "languages": ["hindi", "bengali", "tamil", "telugu", "marathi"],
            "tips": [
                "Use Devanagari/native script consistently",
                "Avoid mixing scripts (Hindi in Latin)",
                "Account for lower model performance",
                "Simpler prompts often work better"
            ]
        },
        "southeast_asian": {
            "languages": ["thai", "vietnamese", "indonesian", "malay"],
            "tips": [
                "Indonesian/Malay use Latin script (efficient)",
                "Thai has no spaces - word boundaries unclear",
                "Vietnamese tones critical for meaning",
                "Simpler prompt structures recommended"
            ]
        }
    }
    
    @classmethod
    def get_optimization_tips(cls, language: str) -> list[str]:
        """Get optimization tips for a language."""
        
        for family, data in cls.strategies.items():
            if language.lower() in data["languages"]:
                return data["tips"]
        
        return ["No specific optimizations available - use general best practices"]
```

### Concise Prompting for High-Token Languages

```python
# For Japanese, Chinese, Korean: minimize prompt tokens

# âŒ Verbose prompt (expensive in CJK)
verbose_japanese_prompt = """
ã‚ãªãŸã¯è¦ªåˆ‡ã§çŸ¥è­˜è±Šå¯Œãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•ã«å¯¾ã—ã¦ã€ã§ãã‚‹ã ã‘è©³ã—ãã€
ã‚ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„ã€‚
å¿…è¦ã«å¿œã˜ã¦ä¾‹ã‚’æŒ™ã’ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
å›ç­”ã¯æ—¥æœ¬èªã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
"""

# âœ… Concise prompt (same effect, fewer tokens)
concise_japanese_prompt = """
å½¹å‰²ï¼šè¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ
å½¢å¼ï¼šè©³ç´°ã‹ã¤æ˜ç¢º
è¨€èªï¼šæ—¥æœ¬èª
ä¾‹ã‚’å«ã‚€ã“ã¨
"""

# Token savings: ~50-60% reduction
```

### Language-Specific Examples

```python
# Provide examples in target language for best results

multi_language_examples = {
    "task": "Summarize in 3 bullet points",
    "examples": {
        "english": """
Input: The new product launch exceeded expectations with 150% of projected sales...
Output:
â€¢ Sales exceeded projections by 50%
â€¢ Customer feedback was overwhelmingly positive
â€¢ Q2 targets have been revised upward
""",
        "japanese": """
å…¥åŠ›: æ–°è£½å“ã®ç™ºå£²ã¯äºˆæƒ³ã‚’ä¸Šå›ã‚Šã€äºˆæ¸¬å£²ä¸Šã®150%ã‚’é”æˆ...
å‡ºåŠ›:
â€¢ å£²ä¸Šã¯äºˆæ¸¬ã‚’50%ä¸Šå›ã£ãŸ
â€¢ é¡§å®¢ã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯éå¸¸ã«å¥½è©•
â€¢ ç¬¬2å››åŠæœŸã®ç›®æ¨™ãŒä¸Šæ–¹ä¿®æ­£ã•ã‚ŒãŸ
""",
        "spanish": """
Entrada: El lanzamiento del nuevo producto superÃ³ las expectativas con 150% de las ventas proyectadas...
Salida:
â€¢ Las ventas superaron las proyecciones en un 50%
â€¢ Los comentarios de los clientes fueron abrumadoramente positivos
â€¢ Los objetivos del segundo trimestre se han revisado al alza
"""
    }
}
```

---

## Hands-on Exercise

### Your Task

Create a tokenization cost calculator that recommends the most cost-effective prompting strategy for different language pairs.

**Requirements:**
1. Calculate token costs for direct prompting vs English-intermediate
2. Account for quality trade-offs (performance tiers from Lesson 00)
3. Provide a recommendation with reasoning

<details>
<summary>ğŸ’¡ Hints (click to expand)</summary>

- Direct Japanese: High quality, high token cost
- English intermediate: Lower cost, but quality loss on translation
- Consider use case: Customer-facing vs internal might have different quality needs

</details>

<details>
<summary>âœ… Solution (click to expand)</summary>

```python
from dataclasses import dataclass
from enum import Enum

class PromptingStrategy(Enum):
    DIRECT_NATIVE = "direct_native"
    ENGLISH_INTERMEDIATE = "english_intermediate"
    HYBRID = "hybrid"

@dataclass
class LanguageProfile:
    name: str
    tier: int  # 1-5 based on Claude performance
    quality_score: float  # 0-1, relative to English
    token_multiplier: float  # Cost relative to English

LANGUAGE_PROFILES = {
    "english": LanguageProfile("English", 1, 1.00, 1.0),
    "spanish": LanguageProfile("Spanish", 1, 0.98, 1.0),
    "french": LanguageProfile("French", 1, 0.98, 1.0),
    "german": LanguageProfile("German", 1, 0.98, 1.05),
    "japanese": LanguageProfile("Japanese", 2, 0.97, 2.7),
    "chinese": LanguageProfile("Chinese", 2, 0.97, 3.3),
    "korean": LanguageProfile("Korean", 2, 0.97, 2.2),
    "arabic": LanguageProfile("Arabic", 2, 0.97, 2.0),
    "hindi": LanguageProfile("Hindi", 2, 0.97, 2.7),
    "thai": LanguageProfile("Thai", 3, 0.93, 4.0),
    "swahili": LanguageProfile("Swahili", 4, 0.90, 1.5),
    "yoruba": LanguageProfile("Yoruba", 5, 0.80, 2.0),
}

@dataclass
class StrategyRecommendation:
    strategy: PromptingStrategy
    estimated_cost_ratio: float
    estimated_quality: float
    reasoning: str

def recommend_strategy(
    source_language: str,
    target_language: str,
    quality_priority: float = 0.5  # 0 = cost priority, 1 = quality priority
) -> StrategyRecommendation:
    """Recommend the best prompting strategy for a language pair."""
    
    source = LANGUAGE_PROFILES.get(source_language.lower())
    target = LANGUAGE_PROFILES.get(target_language.lower())
    
    if not source or not target:
        return StrategyRecommendation(
            strategy=PromptingStrategy.ENGLISH_INTERMEDIATE,
            estimated_cost_ratio=1.0,
            estimated_quality=0.8,
            reasoning="Unknown language - defaulting to English intermediate"
        )
    
    # Calculate direct native approach
    direct_cost = source.token_multiplier + target.token_multiplier
    direct_quality = min(source.quality_score, target.quality_score)
    
    # Calculate English intermediate approach
    # Source â†’ English â†’ Target (2 translation steps)
    english = LANGUAGE_PROFILES["english"]
    intermediate_cost = (
        source.token_multiplier +  # Source input
        english.token_multiplier +  # English reasoning
        target.token_multiplier     # Target output
    )
    # Quality degrades through translation
    intermediate_quality = source.quality_score * target.quality_score * 0.95
    
    # Hybrid: Use English for complex reasoning, target for output
    hybrid_cost = (
        english.token_multiplier * 0.5 +  # Some English prompting
        source.token_multiplier * 0.5 +   # Some native prompting
        target.token_multiplier           # Target output
    )
    hybrid_quality = (direct_quality + intermediate_quality) / 2
    
    # Score each strategy
    def score(cost: float, quality: float) -> float:
        # Normalize cost (lower is better)
        cost_score = 1 / cost
        # Weight by priority
        return (quality * quality_priority) + (cost_score * (1 - quality_priority))
    
    strategies = {
        PromptingStrategy.DIRECT_NATIVE: (direct_cost, direct_quality),
        PromptingStrategy.ENGLISH_INTERMEDIATE: (intermediate_cost, intermediate_quality),
        PromptingStrategy.HYBRID: (hybrid_cost, hybrid_quality),
    }
    
    best_strategy = max(
        strategies.items(),
        key=lambda x: score(x[1][0], x[1][1])
    )
    
    # Generate reasoning
    strategy, (cost, quality) = best_strategy
    
    if strategy == PromptingStrategy.DIRECT_NATIVE:
        reasoning = (
            f"Direct native prompting recommended. "
            f"Quality is high ({quality:.0%}) and cost is reasonable "
            f"({cost:.1f}x English baseline)."
        )
    elif strategy == PromptingStrategy.ENGLISH_INTERMEDIATE:
        reasoning = (
            f"English intermediate recommended. "
            f"Cost savings ({cost:.1f}x vs direct) outweigh "
            f"quality trade-off ({quality:.0%})."
        )
    else:
        reasoning = (
            f"Hybrid approach recommended. "
            f"Balances quality ({quality:.0%}) and cost ({cost:.1f}x) "
            f"by using English for complex logic."
        )
    
    return StrategyRecommendation(
        strategy=strategy,
        estimated_cost_ratio=cost,
        estimated_quality=quality,
        reasoning=reasoning
    )

# Examples
print("=== Japanese to Japanese (Internal Processing) ===")
rec = recommend_strategy("japanese", "japanese", quality_priority=0.3)
print(f"Strategy: {rec.strategy.value}")
print(f"Reasoning: {rec.reasoning}")
print()

print("=== English to Japanese (Customer Facing) ===")
rec = recommend_strategy("english", "japanese", quality_priority=0.8)
print(f"Strategy: {rec.strategy.value}")
print(f"Reasoning: {rec.reasoning}")
print()

print("=== Yoruba to Arabic (Both Lower Tier) ===")
rec = recommend_strategy("yoruba", "arabic", quality_priority=0.5)
print(f"Strategy: {rec.strategy.value}")
print(f"Reasoning: {rec.reasoning}")
```

**Output:**
```
=== Japanese to Japanese (Internal Processing) ===
Strategy: english_intermediate
Reasoning: English intermediate recommended. Cost savings (4.7x vs direct) 
outweigh quality trade-off (89%).

=== English to Japanese (Customer Facing) ===
Strategy: direct_native
Reasoning: Direct native prompting recommended. Quality is high (97%) and 
cost is reasonable (3.7x English baseline).

=== Yoruba to Arabic (Both Lower Tier) ===
Strategy: english_intermediate
Reasoning: English intermediate recommended. Cost savings (4.0x vs direct) 
outweigh quality trade-off (68%).
```

</details>

---

## Summary

âœ… **Word order matters:** SOV languages need different prompt structures than SVO
âœ… **Formality is critical:** Japanese keigo, Korean speech levels require explicit specification
âœ… **Scripts affect costs:** CJK languages cost 2-3x more tokens than Latin scripts
âœ… **RTL requires care:** Arabic, Hebrew need special handling for mixed content
âœ… **Optimize for language family:** Different strategies for Latin, CJK, Indic languages
âœ… **Balance cost vs quality:** Use tokenization data to make informed decisions

**Next:** [Translation in Prompt Pipelines](./04-translation-pipelines.md)

---

## Further Reading

- [OpenAI Tokenizer Tool](https://platform.openai.com/tokenizer) - Visualize tokenization
- [Unicode Technical Reports](https://www.unicode.org/reports/) - Script specifications
- [Japanese Keigo Guide](https://www.japanesewithanime.com/p/keigo.html) - Honorific system

---

<!-- 
Sources Consulted:
- Anthropic Multilingual Support: Performance tiers and language capabilities
- OpenAI Tokenization documentation: Token efficiency by script
- Unicode Consortium: Script specifications and RTL handling
- Language-specific formality research: Keigo, Korean speech levels
-->
