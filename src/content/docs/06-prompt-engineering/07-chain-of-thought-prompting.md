---
title: "Chain-of-Thought Prompting"
---

# Chain-of-Thought Prompting

- What is chain-of-thought?
  - Explicit reasoning in output
  - Step-by-step problem solving
  - Showing the "work"
  - Improved accuracy through reasoning
- Eliciting reasoning steps
  - Trigger phrases
  - Example-based elicitation
  - Structured reasoning requests
  - Reasoning format specification
- Step-by-step instructions
  - Breaking down complex tasks
  - Intermediate checkpoints
  - Self-verification steps
  - Final answer extraction
- "Let's think step by step" technique
  - Zero-shot CoT prompting
  - Automatic reasoning trigger
  - Effectiveness across tasks
  - Combining with other techniques
- **When NOT to Use Chain-of-Thought**
  - ‚ùå With reasoning models (o3, o4-mini, GPT-5)
  - Reasoning models do internal chain-of-thought automatically
  - Adding "think step by step" can reduce performance
  - Let reasoning models determine their own approach
  - Reserve CoT prompting for GPT-4.1 and similar non-reasoning models
- When to use chain-of-thought
  - Complex reasoning tasks (for non-reasoning models)
  - Math and logic problems
  - Multi-step analysis
  - When accuracy matters more than speed
- Verification and self-correction
  - Self-checking prompts
  - "Verify your answer"
  - Error detection in reasoning
  - Correction instructions
