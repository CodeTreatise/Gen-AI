---
title: "25.7 Open-Source Fine-Tuning Concepts"
---

# 25.7 Open-Source Fine-Tuning Concepts

- Hugging Face ecosystem
  - Transformers library
  - Model Hub
  - Trainer API
  - Community resources
- LoRA and PEFT methods
  - LoRA explanation
  - PEFT library
  - Adapter methods
  - Efficiency benefits
- Compute requirements
  - GPU requirements
  - Memory needs
  - Training time
  - Cost estimation
- Local vs. cloud training
  - Local setup
  - Cloud platforms
  - Cost comparison
  - Use case fit
- Model hosting after training
  - Self-hosting options
  - Inference services
  - API setup
  - Scaling considerations
