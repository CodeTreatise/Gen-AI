---
title: "Unit 24: Machine Learning Frameworks"
---

# Unit 24: Machine Learning Frameworks

## Overview & Importance

Machine learning frameworks provide the foundation for training, fine-tuning, and deploying AI models in the modern AI era. While many developers work primarily with pre-trained models via APIs, understanding PyTorch 2.x, TensorFlow, the Hugging Face ecosystem, and modern inference engines enables deeper customization, fine-tuning, and production optimization â€” skills that differentiate senior AI engineers.

ML frameworks matter because:
- Required for fine-tuning and custom models
- PyTorch 2.x is the dominant framework for AI research and production
- Hugging Face is essential for working with transformer models
- Understanding enables optimization of AI applications
- Foundation for advanced AI development (RLHF, DPO, GRPO)
- Necessary for on-device and edge AI (ExecuTorch)
- Modern inference (vLLM, SGLang) requires framework knowledge
- Career advancement in AI requires moving beyond API-only work

## Prerequisites

- Strong Python fundamentals (Unit 2)
- NumPy and Pandas proficiency (Unit 2)
- AI/LLM fundamentals (Unit 1)
- Basic understanding of neural networks
- GPU availability for hands-on practice (local or cloud)
- Familiarity with command-line tools

## Learning Objectives

By the end of this unit, you will be able to:
- Work with PyTorch 2.x tensors and operations
- Leverage torch.compile for performance optimization
- Build and train neural networks in PyTorch
- Use TensorFlow/Keras for model development
- Navigate the Hugging Face ecosystem effectively
- Load and use pre-trained transformer models
- Prepare datasets for training and fine-tuning
- Implement transfer learning techniques
- Apply efficient fine-tuning methods (LoRA, QLoRA, PEFT)
- Use TRL for RLHF training (GRPO, DPO, RLOO)
- Fine-tune with Unsloth and Axolotl frameworks
- Apply modern quantization techniques (FP8, QAT, GGUF)
- Deploy models with vLLM and SGLang inference engines
- Use ExecuTorch for edge and mobile deployment
- Understand state space models and hybrid architectures
- Work with GPU acceleration and distributed training

## Sub-topics

1. [Deep Learning Foundations](01-deep-learning-foundations.md) - 24.1
2. [PyTorch 2.x Fundamentals](02-pytorch-fundamentals.md) - 24.2
3. [PyTorch Neural Networks](03-pytorch-neural-networks.md) - 24.3
4. [Training Loop](04-training-loop.md) - 24.4
5. [Data Loading](05-data-loading.md) - 24.5
6. [TensorFlow/Keras](06-tensorflow-keras.md) - 24.6
7. [Hugging Face Transformers v5](07-hugging-face-transformers.md) - 24.7
8. [Hugging Face Datasets](08-hugging-face-datasets.md) - 24.8
9. [Transfer Learning](09-transfer-learning.md) - 24.9
10. [Training & Evaluation](10-training-evaluation.md) - 24.10
11. [GPU & Distributed Training](11-gpu-distributed-training.md) - 24.11
12. [Efficient Fine-Tuning (PEFT)](12-peft-lora-qlora.md) - 24.12
13. [torch.compile & TorchDynamo](13-torch-compile.md) - 24.13
14. [TRL for RLHF Training](14-trl-rlhf.md) - 24.14
15. [Fine-Tuning Frameworks](15-fine-tuning-frameworks.md) - 24.15
16. [Modern Quantization](16-quantization.md) - 24.16
17. [LLM Inference Serving](17-llm-inference-serving.md) - 24.17
18. [ExecuTorch & Edge Deployment](18-executorch-edge.md) - 24.18
19. [State Space Models & Hybrid Architectures](19-state-space-models.md) - 24.19
20. [Triton & Custom GPU Kernels](20-triton-gpu-kernels.md) - 24.20
21. [Model Export & Production Deployment](21-model-export-production.md) - 24.21

## Market Demand & Relevance

- PyTorch 2.x and torch.compile are the industry standard
- Hugging Face experience specifically mentioned in 90%+ AI job postings
- Fine-tuning skills (LoRA, QLoRA) command 20-30% salary premiums
- TRL and RLHF expertise highly sought for alignment roles
- vLLM deployment skills essential for inference engineering
- ML framework knowledge differentiates senior AI roles
- Required for ML Engineer, AI Researcher, and MLOps positions
- Growing demand for Unsloth/Axolotl expertise
- Edge AI (ExecuTorch) emerging as key mobile AI skill
- Enterprise increasingly needs custom model capabilities

---

*Estimated study time: 90-110 hours*
*Hands-on practice recommended: 60+ hours*
*GPU access required for meaningful practice*
