---
title: "Similarity Search"
---

# Similarity Search

- Query embedding generation
  - MUST use same model as documents
  - MUST use appropriate task_type (RETRIEVAL_QUERY)
  - Query preprocessing (cleaning, expansion)
  - Query expansion with LLM
  - Caching frequent query embeddings
- Top-k retrieval strategies
  - Choosing k value (start with 10-20)
  - Over-fetch for re-ranking (fetch 100, rerank to 10)
  - Pagination patterns for large results
  - Performance vs recall trade-offs
- Similarity thresholds
  - Minimum similarity cutoffs (0.7-0.8 typical)
  - Dynamic thresholds based on query
  - Quality filtering approaches
  - Empty result handling strategies
  - Fallback to keyword search
- Filtering by metadata
  - Pre-filter vs post-filter trade-offs
  - Filter syntax per database
  - Complex filter logic (AND, OR, NOT)
  - Performance impact of filtering
  - Index design for filtered queries
- Hybrid search (BM25 + semantic)
  - Why hybrid outperforms pure semantic
  - BM25 for exact matches and rare terms
  - Score fusion methods:
    - Reciprocal Rank Fusion (RRF)
    - Distribution-Based Score Fusion (DBSF)
    - Weighted linear combination
    - Convex combination
  - Implementation approaches by database
  - Tuning hybrid weights
- Learned Sparse Embeddings (SPLADE)
  - Beyond traditional BM25
  - SPLADE: Sparse Lexical and Expansion model
  - Term expansion: identify related terms not in original text
  - Solves vocabulary mismatch problem
  - Models: splade-cocondenser-ensembledistil
  - Pinecone sparse indexes, Qdrant sparse vectors
  - When SPLADE beats BM25
  - Combine with dense for best results
- Contextual BM25 (Anthropic method)
  - Adding context before BM25 indexing
  - Same context added to embeddings
  - Combined with Contextual Embeddings
  - 49% improvement in retrieval
- Re-ranking results (2025 models)
  - Why re-rank: precision over recall
  - Cross-encoder vs bi-encoder
  - Cohere Rerank v3 API
  - Voyage Reranker
  - Jina Reranker
  - BGE Reranker (open source)
  - Two-stage retrieval architecture
  - Cost-latency trade-offs
- Reranked Contextual Retrieval
  - Anthropic's full pipeline
  - Contextual Embeddings + Contextual BM25 + Reranking
  - 67% reduction in retrieval failures
  - Implementation considerations
- Maximal Marginal Relevance (MMR)
  - Problem: redundant/similar results
  - MMR balances relevance and diversity
  - Formula: λ*sim(query) - (1-λ)*max_sim(selected)
  - diversity parameter: 0.0 (relevance) to 1.0 (diversity)
  - Qdrant: built-in MMR query support
  - Use cases: diverse recommendations, varied search results
  - candidates_limit for performance
