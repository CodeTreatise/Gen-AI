---
title: "Generating Embeddings"
---

# Generating Embeddings

- API calls for embedding generation
  - Request format and required parameters
  - Response parsing (embedding array extraction)
  - Model specification best practices
  - Error handling and retries
  - Rate limit awareness
- Task-type specification (critical for quality)
  - Gemini task_type parameter:
    - RETRIEVAL_QUERY: for search queries
    - RETRIEVAL_DOCUMENT: for documents being searched
    - SEMANTIC_SIMILARITY: for comparing text pairs
    - CLASSIFICATION: for categorization tasks
    - CLUSTERING: for grouping similar items
    - CODE_RETRIEVAL_QUERY: for code search
    - QUESTION_ANSWERING: for Q&A systems
    - FACT_VERIFICATION: for fact-checking
  - Cohere input_type parameter:
    - search_query vs search_document
    - classification, clustering
  - OpenAI: no task type (general purpose)
- Dimension control at API level
  - OpenAI dimensions parameter (text-embedding-3)
  - Gemini output_dimensionality parameter
  - Cohere output_dimension parameter
  - Matryoshka dimension selection
  - IMPORTANT: Normalize after dimension reduction
- Batch embedding processing
  - Batch API for cost savings (Gemini 50% off)
  - Optimal batch sizes (100-2000 texts)
  - Rate limit management strategies
  - Progress tracking for large jobs
  - Async processing patterns
- Input text preparation
  - Text cleaning and normalization
  - Encoding considerations (UTF-8)
  - Special character handling
  - Length validation before API call
  - Prefix strategies (query: vs passage:)
- Handling long texts
  - Context length limits per model
  - Text truncation strategies (start, end, middle)
  - Splitting and combining approaches
  - Mean pooling for multiple chunks
  - Weighted pooling strategies
- Embedding normalization
  - Why normalization matters
  - L2 normalization for cosine similarity
  - Truncated dimensions MUST be renormalized
  - Pre-normalized vs manual normalization
- Embedding caching strategies
  - Cache key design (text hash + model + dimensions)
  - Storage options (Redis, file, database)
  - Cache invalidation on model updates
  - TTL considerations
  - Cost-benefit analysis of caching
